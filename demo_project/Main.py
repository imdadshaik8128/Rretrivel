"""
main.py â€” End-to-end CLI Runner
=================================
Pipeline:
    user query
        â”‚
        â–¼
    query_parser_v2   (SLM â€” extracts metadata)
        â”‚
        â–¼
    Retriever         (metadata filter â†’ bi-encoder â†’ cross-encoder)
        â”‚
        â–¼
    Generator         (Ollama local LLM â†’ dual format answer)
        â”‚
        â”œâ”€â”€â–º Terminal display  (markdown rendered in terminal)
        â””â”€â”€â–º pyttsx3 TTS       (speaks the spoken_answer)

Install dependencies:
    pip install pyttsx3 rich requests sentence-transformers
    ollama pull qwen2.5:0.5b-instruct
"""

from __future__ import annotations

import json
import sys
import time

# â”€â”€ Terminal markdown renderer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 'rich' renders markdown beautifully in the terminal.
# Install: pip install rich
try:
    from rich.console import Console
    from rich.markdown import Markdown
    from rich.panel import Panel
    from rich.rule import Rule
    from rich.text import Text
    from rich import print as rprint
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False

# â”€â”€ TTS engine â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# pyttsx3 works fully offline, no API key, no internet.
# Install: pip install pyttsx3
# On Linux also: sudo apt-get install espeak
try:
    import pyttsx3
    TTS_AVAILABLE = True
except ImportError:
    TTS_AVAILABLE = False

from retriever import Retriever, AmbiguityError
from generator import Generator

# â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TTS_RATE      = 165    # words per minute (default ~200, slower = clearer)
TTS_VOLUME    = 0.9    # 0.0 â€“ 1.0
DIVIDER       = "â•" * 65


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Terminal display helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

console = Console() if RICH_AVAILABLE else None


def _print(text: str, style: str = ""):
    if RICH_AVAILABLE:
        console.print(text, style=style)
    else:
        print(text)


def _rule(title: str = ""):
    if RICH_AVAILABLE:
        console.print(Rule(title, style="bold cyan"))
    else:
        print(f"\n{'â”€' * 65}  {title}")


def display_answer(answer) -> None:
    """
    Renders the GeneratedAnswer to terminal.
    Uses 'rich' for markdown if available, falls back to plain print.
    """
    _rule()

    # â”€â”€ Answer type badge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    badge = (
        "[bold green]â— REFERENCE LOOKUP[/bold green]"
        if answer.answer_type == "reference"
        else "[bold blue]â— CONCEPT EXPLANATION[/bold blue]"
    )
    if RICH_AVAILABLE:
        console.print(badge)
    else:
        print(f"[ {answer.answer_type.upper()} ]")

    # â”€â”€ Low confidence warning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if answer.low_confidence_warning:
        if RICH_AVAILABLE:
            console.print(
                Panel(
                    f"âš   {answer.low_confidence_warning}",
                    style="bold yellow",
                    title="Low Confidence Warning",
                )
            )
        else:
            print(f"\nâš   WARNING: {answer.low_confidence_warning}")

    # â”€â”€ Confidence bar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pct = int(answer.confidence * 100)
    bar = "â–ˆ" * (pct // 5) + "â–‘" * (20 - pct // 5)
    conf_line = f"Confidence: [{bar}] {pct}%"
    _print(conf_line, style="dim")

    # â”€â”€ Display answer (markdown) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _rule("DISPLAY ANSWER")
    if RICH_AVAILABLE:
        console.print(Markdown(answer.display_answer_markdown))
    else:
        # Plain fallback â€” strip common markdown symbols
        import re
        plain = re.sub(r"#{1,6}\s+", "", answer.display_answer_markdown)
        plain = re.sub(r"\*{1,3}(.+?)\*{1,3}", r"\1", plain)
        plain = re.sub(r"`(.+?)`", r"\1", plain)
        print(plain)

    # â”€â”€ Citations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if answer.citations:
        _rule("SOURCES")
        for i, c in enumerate(answer.citations, 1):
            line = (
                f"  [{i}] Chapter {c.chapter_number}"
                + (f" â€” {c.section_title}" if c.section_title else "")
                + (f"  (Activity {c.activity_number})" if c.activity_number.strip() not in ("", "None") else "")
                + f"  [{c.chunk_type}]"
            )
            _print(line, style="dim cyan")

    # â”€â”€ Filter path (provenance) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _print(f"\n  Filter path : {answer.filter_path}", style="dim")
    _rule()


def display_spoken_text(spoken: str) -> None:
    """Show the spoken answer in terminal before/during TTS."""
    _rule("SPOKEN ANSWER  (TTS)")
    if RICH_AVAILABLE:
        console.print(
            Panel(spoken, style="italic green", title="ðŸ”Š Speaking â€¦")
        )
    else:
        print(f"\nðŸ”Š {spoken}\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TTS engine
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _init_tts():
    """Initialise pyttsx3 engine with configured rate and volume."""
    if not TTS_AVAILABLE:
        return None
    try:
        engine = pyttsx3.init()
        engine.setProperty("rate",   TTS_RATE)
        engine.setProperty("volume", TTS_VOLUME)

        # Pick a clear voice if multiple are available
        voices = engine.getProperty("voices")
        if voices:
            # Prefer English voice
            for v in voices:
                if "english" in v.name.lower() or "en" in v.id.lower():
                    engine.setProperty("voice", v.id)
                    break

        return engine
    except Exception as e:
        print(f"âš   TTS init failed: {e}")
        return None


def speak(engine, text: str) -> None:
    """Speak text using pyttsx3. Silently skips if engine is unavailable."""
    if engine is None:
        _print("  (TTS unavailable â€” install pyttsx3 and espeak)", style="dim yellow")
        return
    try:
        engine.say(text)
        engine.runAndWait()
    except Exception as e:
        _print(f"  (TTS error: {e})", style="dim yellow")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main pipeline
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_pipeline(
    query:     str,
    retriever: Retriever,
    generator: Generator,
    tts_engine,
) -> None:
    """
    Full pipeline for one query:
      parse â†’ retrieve â†’ generate â†’ display â†’ speak
    """
    print(f"\n{DIVIDER}")
    _print(f"  Query : {query}", style="bold white")
    print(DIVIDER)

    # â”€â”€ Step 1: Parse query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        from query_parser_v2 import parse_query_with_slm
        raw_parse  = parse_query_with_slm(query)
        parsed_dict = json.loads(raw_parse)
        _print(f"  Parsed : {json.dumps(parsed_dict)}", style="dim")
    except Exception as e:
        _print(f"  âš   Query parser error: {e}", style="bold red")
        return

    # â”€â”€ Step 2: Retrieve chunks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _print("\n  Retrieving chunks â€¦", style="dim")
    t0 = time.perf_counter()
    chunks, ret_err = retriever.retrieve_safe(parsed_dict, query)
    retrieval_ms = int((time.perf_counter() - t0) * 1000)

    if ret_err:
        _print(f"\n  âš   Retrieval failed: {ret_err}", style="bold red")
        _print(
            "  â†’ Check subject name, chapter number, or activity number.",
            style="yellow",
        )
        return

    _print(
        f"  Retrieved {len(chunks)} chunks in {retrieval_ms}ms",
        style="dim green",
    )

    # â”€â”€ Step 3: Generate answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _print("\n  Generating answer via Ollama â€¦", style="dim")
    t1 = time.perf_counter()
    answer, gen_err = generator.generate_safe(chunks, query)
    generation_ms = int((time.perf_counter() - t1) * 1000)

    if gen_err:
        _print(f"\n  âš   Generation failed: {gen_err}", style="bold red")
        if "not running" in gen_err:
            _print(
                "  â†’ Start Ollama:  ollama serve",
                style="yellow",
            )
            _print(
                "  â†’ Pull model  :  ollama pull qwen2.5:0.5b-instruct",
                style="yellow",
            )
        return

    _print(
        f"  Generated in {generation_ms}ms  |  "
        f"type={answer.answer_type}  |  "
        f"confidence={answer.confidence:.0%}",
        style="dim green",
    )

    # â”€â”€ Step 4: Display â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    display_answer(answer)

    # â”€â”€ Step 5: TTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    display_spoken_text(answer.spoken_answer)
    speak(tts_engine, answer.spoken_answer)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Interactive REPL loop
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    _print("\n  Initialising system â€¦", style="bold cyan")

    # Load retriever once (embeddings computed at startup)
    _print("  Loading retriever (bi-encoder + cross-encoder) â€¦", style="dim")
    retriever = Retriever()

    # Generator is stateless
    generator = Generator()

    # Init TTS
    _print("  Initialising TTS engine (pyttsx3) â€¦", style="dim")
    tts_engine = _init_tts()

    if not TTS_AVAILABLE:
        _print(
            "  âš   pyttsx3 not installed. Spoken answer will be shown but not spoken.\n"
            "     Install: pip install pyttsx3\n"
            "     Linux  : sudo apt-get install espeak",
            style="yellow",
        )

    _print("\n  âœ“ System ready.\n", style="bold green")
    _print("  Type your question and press Enter.", style="dim")
    _print("  Commands:  'quit' or 'exit' to stop  |  'json' to see raw output\n", style="dim")

    show_json = False  # toggle with 'json' command

    while True:
        try:
            # Prompt
            if RICH_AVAILABLE:
                console.print("[bold cyan]You >[/bold cyan] ", end="")
                query = input()
            else:
                query = input("You > ")

            query = query.strip()

            if not query:
                continue

            if query.lower() in ("quit", "exit", "q"):
                _print("\n  Goodbye!\n", style="bold cyan")
                break

            # Toggle raw JSON output
            if query.lower() == "json":
                show_json = not show_json
                state = "ON" if show_json else "OFF"
                _print(f"  Raw JSON output: {state}", style="dim yellow")
                continue

            # Run the full pipeline
            run_pipeline(query, retriever, generator, tts_engine)

            # Optionally show raw JSON
            if show_json:
                _rule("RAW JSON OUTPUT")
                # Re-run just generator to get the dict (last answer not stored)
                # Better: store last answer in run_pipeline
                _print("  (Run with json mode â€” last answer above)", style="dim")

        except KeyboardInterrupt:
            _print("\n\n  Interrupted. Type 'quit' to exit.\n", style="yellow")
            continue
        except EOFError:
            break


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Single-query mode (pass query as CLI argument)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # Single query mode: python main.py "explain activity 2 chapter 3 biology"
        single_query = " ".join(sys.argv[1:])

        retriever  = Retriever()
        generator  = Generator()
        tts_engine = _init_tts()

        run_pipeline(single_query, retriever, generator, tts_engine)
    else:
        # Interactive REPL mode: python main.py
        main()